{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOuGOCxSbYhQkHGd4NKC1V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nisha1365/TECHNICAL_TRAINING_CTS/blob/main/SageMaker_TimeSeries_With_DeepAR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNO91KQhm923"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import patplotlib.pyplot as plt\n",
        "import boto3\n",
        "import sagemaker\n",
        "import sagemaker import get_execution_role\n",
        "\n",
        "np.random.seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"sagemaker/deepar\"\n",
        "\n",
        "sagemaker_session = sagemaker.Session()\n",
        "role = get_execution_role()\n",
        "bucket = sagemaker_session.default_bucket()\n",
        "\n",
        "s3_data_path = f\"{bucket}/{prefix}/data\"\n",
        "s3_output_path = f\"{bucket}/{prefix}/output\""
      ],
      "metadata": {
        "id": "-CgBRPS9qf8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "configure the container image to be used for the region that we are running in"
      ],
      "metadata": {
        "id": "McqkbRvLr1_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_uri = sagemaker.image_uris.retrieve(\"forcasting-deepar\", boto3.Session().region_name)"
      ],
      "metadata": {
        "id": "igR7Jle0r8VQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freq = \"H\"\n",
        "prediction_length = 48"
      ],
      "metadata": {
        "id": "rA3ugfhssyPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_lengh = 72"
      ],
      "metadata": {
        "id": "KMU3CdLIujaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "generate 200 noisy time series, each consisting of 400 data points and with seasonality of 24 hours"
      ],
      "metadata": {
        "id": "BuXcRD7pwE1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = \"2016-01-01 00:00:00\"\n",
        "data_length = 400\n",
        "num_ts = 200\n",
        "period = 24"
      ],
      "metadata": {
        "id": "hb4RJ0pUwM_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The time series in general will be noisy sine wave with random level"
      ],
      "metadata": {
        "id": "P937Sy-MwhdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "time_series = []\n",
        "for k in range(num_ts):\n",
        "    level = 10 * np.random.rand()\n",
        "    seas_amplitude = (0.1 + 0.3 * np.random.rand()) * level\n",
        "    sig = 0.05 * level  # noise parameter (constant in time)\n",
        "    time_ticks = np.array(range(data_length))\n",
        "    source = level + seas_amplitude * np.sin(time_ticks * (2 * np.pi) / period)\n",
        "    noise = sig * np.random.randn(data_length)\n",
        "    data = source + noise\n",
        "    index = pd.date_range(start=t0, freq=freq, periods=data_length)\n",
        "    time_series.append(pd.Series(data=data, index=index))"
      ],
      "metadata": {
        "id": "nxNrG531ullU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_series[0].plot()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kaEfpd74xkv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_series_training = []\n",
        "for ts in time_series:\n",
        "  time_series_training.append(ts[:-prediction_length])"
      ],
      "metadata": {
        "id": "o8UW4kCEyT1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_series[0].plot(label = \"test\")\n",
        "time_series_training[0].plot(label = \"train\", ls= \":\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ovay45zQyvkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def series_to_obj(ts, cat=None):\n",
        "    obj = {\"start\": str(ts.index[0]), \"target\": list(ts)}\n",
        "    if cat is not None:\n",
        "        obj[\"cat\"] = cat\n",
        "    return obj\n",
        " \n",
        "\n",
        "def series_to_jsonline(ts, cat=None):\n",
        "    return json.dumps(series_to_obj(ts, cat))"
      ],
      "metadata": {
        "id": "lJrEs2zMzPEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = \"utf-8\"\n",
        "FILE_TRAIN = \"train.json\"\n",
        "FILE_TEST = \"test.json\"\n",
        "with open(FILE_TRAIN, \"wb\") as f:\n",
        "    for ts in time_series_training:\n",
        "        f.write(series_to_jsonline(ts).encode(encoding))\n",
        "        f.write(\"\\n\".encode(encoding))\n",
        " \n",
        "with open(FILE_TEST, \"wb\") as f:\n",
        "    for ts in time_series:\n",
        "        f.write(series_to_jsonline(ts).encode(encoding))\n",
        "        f.write(\"\\n\".encode(encoding))\n",
        "s3 = boto3.client(\"s3\")\n",
        "s3.upload_file(FILE_TRAIN, bucket, prefix + \"/data/train/\" + FILE_TRAIN)\n",
        "s3.upload_file(FILE_TEST, bucket, prefix + \"/data/test/\" + FILE_TRAIN)"
      ],
      "metadata": {
        "id": "C2_ISKT81Yo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = sagemaker.estimator.Estimator(\n",
        "    sagemaker_session=sagemaker_session,\n",
        "    image_uri=image_uri,\n",
        "    role=role,\n",
        "    instance_count=1,\n",
        "    instance_type=\"ml.m5.xlarge\",\n",
        "    base_job_name=\"deepar\",\n",
        "    output_path=f\"s3://{s3_output_path}\",\n",
        ")"
      ],
      "metadata": {
        "id": "6q2ZAoAF1ujg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameters = {\n",
        "    \"time_freq\": freq,\n",
        "    \"context_length\": str(context_length),\n",
        "    \"prediction_length\": str(prediction_length),\n",
        "    \"num_cells\": \"40\",\n",
        "    \"num_layers\": \"3\",\n",
        "    \"likelihood\": \"gaussian\",\n",
        "    \"epochs\": \"20\",\n",
        "    \"mini_batch_size\": \"32\",\n",
        "    \"learning_rate\": \"0.001\",\n",
        "    \"dropout_rate\": \"0.05\",\n",
        "    \"early_stopping_patience\": \"10\",\n",
        "}"
      ],
      "metadata": {
        "id": "E_CtLcrE2xQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimator.set_hyperparameters(**hyperparameters)"
      ],
      "metadata": {
        "id": "vfCIihOD3o0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_channels = {\"train\": f\"s3://{s3_data_path}/train/\", \"test\" : f\"s3://{s3_data_path}/test/\"}\n",
        "\n",
        "estimator.fit(input = data_channels)"
      ],
      "metadata": {
        "id": "AYsb30-D4Efr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_name = estimator.latest_training_job.name\n",
        " \n",
        "endpoint_name = sagemaker_session.endpoint_from_job(\n",
        "    job_name=job_name,\n",
        "    initial_instance_count=1,\n",
        "    instance_type=\"ml.m5.xlarge\",\n",
        "    image_uri=image_uri,\n",
        "    role=role,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "4V_hZx754sFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepARPredictor(sagemaker.predictor.RealTimePredictor):\n",
        "    def set_prediction_parameters(self, freq, prediction_length):\n",
        "        \"\"\"Set the time frequency and prediction length parameters. This method **must** be called\n",
        "        before being able to use `predict`.\n",
        " \n",
        "        Parameters:\n",
        "        freq -- string indicating the time frequency\n",
        "        prediction_length -- integer, number of predicted time points\n",
        " \n",
        "        Return value: none.\n",
        "        \"\"\"\n",
        "        self.freq = freq\n",
        "        self.prediction_length = prediction_length\n",
        " \n",
        "    def predict(\n",
        "        self,\n",
        "        ts,\n",
        "        cat=None,\n",
        "        encoding=\"utf-8\",\n",
        "        num_samples=100,\n",
        "        quantiles=[\"0.1\", \"0.5\", \"0.9\"],\n",
        "        content_type=\"application/json\",\n",
        "    ):\n",
        "        \"\"\"Requests the prediction of for the time series listed in `ts`, each with the (optional)\n",
        "        corresponding category listed in `cat`.\n",
        " \n",
        "        Parameters:\n",
        "        ts -- list of `pandas.Series` objects, the time series to predict\n",
        "        cat -- list of integers (default: None)\n",
        "        encoding -- string, encoding to use for the request (default: \"utf-8\")\n",
        "        num_samples -- integer, number of samples to compute at prediction time (default: 100)\n",
        "        quantiles -- list of strings specifying the quantiles to compute (default: [\"0.1\", \"0.5\", \"0.9\"])\n",
        " \n",
        "        Return value: list of `pandas.DataFrame` objects, each containing the predictions\n",
        "        \"\"\"\n",
        "        prediction_times = [x.index[-1] + pd.Timedelta(1, unit=self.freq) for x in ts]\n",
        "        req = self.__encode_request(ts, cat, encoding, num_samples, quantiles)\n",
        "        res = super(DeepARPredictor, self).predict(req, initial_args={\"ContentType\": content_type})\n",
        "        return self.__decode_response(res, prediction_times, encoding)\n",
        " \n",
        "    def __encode_request(self, ts, cat, encoding, num_samples, quantiles):\n",
        "        instances = [series_to_obj(ts[k], cat[k] if cat else None) for k in range(len(ts))]\n",
        "        configuration = {\n",
        "            \"num_samples\": num_samples,\n",
        "            \"output_types\": [\"quantiles\"],\n",
        "            \"quantiles\": quantiles,\n",
        "        }\n",
        "        http_request_data = {\"instances\": instances, \"configuration\": configuration}\n",
        "        return json.dumps(http_request_data).encode(encoding)\n",
        " \n",
        "    def __decode_response(self, response, prediction_times, encoding):\n",
        "        response_data = json.loads(response.decode(encoding))\n",
        "        list_of_df = []\n",
        "        for k in range(len(prediction_times)):\n",
        "            prediction_index = pd.date_range(\n",
        "                start=prediction_times[k], freq=self.freq, periods=self.prediction_length\n",
        "            )\n",
        "            list_of_df.append(\n",
        "                pd.DataFrame(\n",
        "                    data=response_data[\"predictions\"][k][\"quantiles\"], index=prediction_index\n",
        "                )\n",
        "            )\n",
        "        return list_of_df"
      ],
      "metadata": {
        "id": "Txu67EdJ6zf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = DeepARPredictor(endpoint_name=endpoint_name, sagemaker_session=sagemaker_session)\n",
        "predictor.set_prediction_parameters(freq, prediction_length)\n",
        "\n"
      ],
      "metadata": {
        "id": "LTDJcQx07aH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_df = predictor.predict(time_series_training[:3], content_type=\"application/json\")\n",
        "actual_data = time_series[:3]"
      ],
      "metadata": {
        "id": "lL_BMXGo774J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(len(list_of_df)):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    actual_data[k][-prediction_length - context_length :].plot(label=\"target\")\n",
        "    p10 = list_of_df[k][\"0.1\"]\n",
        "    p90 = list_of_df[k][\"0.9\"]\n",
        "    plt.fill_between(p10.index, p10, p90, color=\"y\", alpha=0.5, label=\"80% confidence interval\")\n",
        "    list_of_df[k][\"0.5\"].plot(label=\"prediction median\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "9NwQcLY28Q7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zATHVPgA6vcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zJtNU6pA4L_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SxbLLIHt4MH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YFIJ9UGD3_DW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}