{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0yOFYNjIZ/3F+koOgMGP1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nisha1365/TECHNICAL_TRAINING_CTS/blob/main/Nisha_2211566_Assignment_10A_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Topic Modeling\n",
        "\n",
        "### This Project takes a few news group data and indentifies the topic of discussion in each of these groups\n",
        "\n",
        "###  Here we are taking threads from 20 news groups as to reduce processing time"
      ],
      "metadata": {
        "id": "WKm2f2MuXJjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups"
      ],
      "metadata": {
        "id": "wlZY-dayXG9G"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "0ypLqeZEXpm6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newsgroups_train = fetch_20newsgroups(subset='train',shuffle = True)\n",
        "newsgroups_test = fetch_20newsgroups(subset='test',shuffle = True)"
      ],
      "metadata": {
        "id": "1JIW3EGoXuum"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(newsgroups_train.target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zFFsSYqZFXE",
        "outputId": "f9ff8e5b-0d08-429d-bb60-1f1e3e962734"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newsgroups_train.data[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF1YyG3Ycf0w",
        "outputId": "bcb7a770-3a05-4547-e36e-f8c6f876d948"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\",\n",
              " \"From: guykuo@carson.u.washington.edu (Guy Kuo)\\nSubject: SI Clock Poll - Final Call\\nSummary: Final call for SI clock reports\\nKeywords: SI,acceleration,clock,upgrade\\nArticle-I.D.: shelley.1qvfo9INNc3s\\nOrganization: University of Washington\\nLines: 11\\nNNTP-Posting-Host: carson.u.washington.edu\\n\\nA fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll. Thanks.\\n\\nGuy Kuo <guykuo@u.washington.edu>\\n\"]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS"
      ],
      "metadata": {
        "id": "b17fppGIZMDe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcUj52HWZ_sf",
        "outputId": "291d5331-d379-4555-f44f-15c76255b301"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "np.random.seed(400)"
      ],
      "metadata": {
        "id": "p7uxBql8ZNEQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFGwTFGsebXF",
        "outputId": "63d195a8-8718-475b-a68a-67e4b482aef6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfTSAXlgerHY",
        "outputId": "53ed7ead-c6cf-4dbc-f14e-307d4efb149a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(WordNetLemmatizer().lemmatize('went', pos = 'v'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xlWgmOzeckb",
        "outputId": "d52ae957-f329-4a69-c1c4-ba2aa48cc217"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "go\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "stemmer = SnowballStemmer(\"english\")"
      ],
      "metadata": {
        "id": "e0DxiEEid7Km"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_words = ['caresses', 'flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned',\n",
        "           'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational',\n",
        "           'traditional', 'reference', 'colonizer','plotted']\n",
        "singles = [stemmer.stem(plural) for plural in original_words]"
      ],
      "metadata": {
        "id": "XLXZW4gbfNvT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(data={'original word':original_words, 'stemmed':singles })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "LmWy17_mfTHR",
        "outputId": "122c9c80-c570-460b-c9a6-46f6f83bddd9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   original word stemmed\n",
              "0       caresses  caress\n",
              "1          flies     fli\n",
              "2           dies     die\n",
              "3          mules    mule\n",
              "4         denied    deni\n",
              "5           died     die\n",
              "6         agreed    agre\n",
              "7          owned     own\n",
              "8        humbled   humbl\n",
              "9          sized    size\n",
              "10       meeting    meet\n",
              "11       stating   state\n",
              "12       siezing    siez\n",
              "13   itemization    item\n",
              "14   sensational  sensat\n",
              "15   traditional  tradit\n",
              "16     reference   refer\n",
              "17     colonizer   colon\n",
              "18       plotted    plot"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dbdbde7a-ca41-44f9-b852-4077a5c79993\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original word</th>\n",
              "      <th>stemmed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>caresses</td>\n",
              "      <td>caress</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>flies</td>\n",
              "      <td>fli</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dies</td>\n",
              "      <td>die</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mules</td>\n",
              "      <td>mule</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>denied</td>\n",
              "      <td>deni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>died</td>\n",
              "      <td>die</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>agreed</td>\n",
              "      <td>agre</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>owned</td>\n",
              "      <td>own</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>humbled</td>\n",
              "      <td>humbl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>sized</td>\n",
              "      <td>size</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>meeting</td>\n",
              "      <td>meet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>stating</td>\n",
              "      <td>state</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>siezing</td>\n",
              "      <td>siez</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>itemization</td>\n",
              "      <td>item</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>sensational</td>\n",
              "      <td>sensat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>traditional</td>\n",
              "      <td>tradit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>reference</td>\n",
              "      <td>refer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>colonizer</td>\n",
              "      <td>colon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>plotted</td>\n",
              "      <td>plot</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dbdbde7a-ca41-44f9-b852-4077a5c79993')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dbdbde7a-ca41-44f9-b852-4077a5c79993 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dbdbde7a-ca41-44f9-b852-4077a5c79993');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_stemming(text):\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))"
      ],
      "metadata": {
        "id": "vAjlgJRqff7Y"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and lemmatize\n",
        "def preprocess(text):\n",
        "    result=[]\n",
        "    for token in gensim.utils.simple_preprocess(text) :\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "            result.append(lemmatize_stemming(token))\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "tjKgWacehCLu"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_num = 50\n",
        "doc_sample = 'This disk has failed many times. I would like to get it replaced.'"
      ],
      "metadata": {
        "id": "uAXYO45IhFwb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original document: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyUWFYj2hmfb",
        "outputId": "73017f16-089c-4308-be3c-ef4773dd91ec"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original document: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = []\n",
        "for word in doc_sample.split(' '):\n",
        "  words.append(word)\n",
        "\n",
        "print(words)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcP8kDnCixlE",
        "outputId": "e9ce2ef4-ddd5-43a7-e89a-91e9faa87460"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'disk', 'has', 'failed', 'many', 'times.', 'I', 'would', 'like', 'to', 'get', 'it', 'replaced.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\nTokenized and lemmatized document: \")\n",
        "print(preprocess(doc_sample))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPHwUoDgjAUh",
        "outputId": "d1f580d7-2fc3-4ff8-b867-d7aca08f7d2d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Tokenized and lemmatized document: \n",
            "['disk', 'fail', 'time', 'like', 'replac']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_docs = []\n",
        " \n",
        "for doc in newsgroups_train.data:\n",
        "    processed_docs.append(preprocess(doc))\n",
        " \n",
        "print(processed_docs[:2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mnirij7jB1w",
        "outputId": "58176969-35be-474e-aa94-f4e0490888d7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['lerxst', 'thing', 'subject', 'nntp', 'post', 'host', 'organ', 'univers', 'maryland', 'colleg', 'park', 'line', 'wonder', 'enlighten', 'door', 'sport', 'look', 'late', 'earli', 'call', 'bricklin', 'door', 'small', 'addit', 'bumper', 'separ', 'rest', 'bodi', 'know', 'tellm', 'model', 'engin', 'spec', 'year', 'product', 'histori', 'info', 'funki', 'look', 'mail', 'thank', 'bring', 'neighborhood', 'lerxst'], ['guykuo', 'carson', 'washington', 'subject', 'clock', 'poll', 'final', 'summari', 'final', 'clock', 'report', 'keyword', 'acceler', 'clock', 'upgrad', 'articl', 'shelley', 'qvfo', 'innc', 'organ', 'univers', 'washington', 'line', 'nntp', 'post', 'host', 'carson', 'washington', 'fair', 'number', 'brave', 'soul', 'upgrad', 'clock', 'oscil', 'share', 'experi', 'poll', 'send', 'brief', 'messag', 'detail', 'experi', 'procedur', 'speed', 'attain', 'rat', 'speed', 'card', 'adapt', 'heat', 'sink', 'hour', 'usag', 'floppi', 'disk', 'function', 'floppi', 'especi', 'request', 'summar', 'day', 'network', 'knowledg', 'base', 'clock', 'upgrad', 'haven', 'answer', 'poll', 'thank', 'guykuo', 'washington']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = gensim.corpora.Dictionary(processed_docs)"
      ],
      "metadata": {
        "id": "D8pAg2F2jwhQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "count = 0\n",
        "for k, v in dictionary.iteritems():\n",
        "    print(k, v)\n",
        "    count += 1\n",
        "    if count > 100:\n",
        "        break\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TX4DPIX9kEbh",
        "outputId": "b11bb8ff-bbee-4770-f2c1-47d46d9a34c2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 addit\n",
            "1 bodi\n",
            "2 bricklin\n",
            "3 bring\n",
            "4 bumper\n",
            "5 call\n",
            "6 colleg\n",
            "7 door\n",
            "8 earli\n",
            "9 engin\n",
            "10 enlighten\n",
            "11 funki\n",
            "12 histori\n",
            "13 host\n",
            "14 info\n",
            "15 know\n",
            "16 late\n",
            "17 lerxst\n",
            "18 line\n",
            "19 look\n",
            "20 mail\n",
            "21 maryland\n",
            "22 model\n",
            "23 neighborhood\n",
            "24 nntp\n",
            "25 organ\n",
            "26 park\n",
            "27 post\n",
            "28 product\n",
            "29 rest\n",
            "30 separ\n",
            "31 small\n",
            "32 spec\n",
            "33 sport\n",
            "34 subject\n",
            "35 tellm\n",
            "36 thank\n",
            "37 thing\n",
            "38 univers\n",
            "39 wonder\n",
            "40 year\n",
            "41 acceler\n",
            "42 adapt\n",
            "43 answer\n",
            "44 articl\n",
            "45 attain\n",
            "46 base\n",
            "47 brave\n",
            "48 brief\n",
            "49 card\n",
            "50 carson\n",
            "51 clock\n",
            "52 day\n",
            "53 detail\n",
            "54 disk\n",
            "55 especi\n",
            "56 experi\n",
            "57 fair\n",
            "58 final\n",
            "59 floppi\n",
            "60 function\n",
            "61 guykuo\n",
            "62 haven\n",
            "63 heat\n",
            "64 hour\n",
            "65 innc\n",
            "66 keyword\n",
            "67 knowledg\n",
            "68 messag\n",
            "69 network\n",
            "70 number\n",
            "71 oscil\n",
            "72 poll\n",
            "73 procedur\n",
            "74 qvfo\n",
            "75 rat\n",
            "76 report\n",
            "77 request\n",
            "78 send\n",
            "79 share\n",
            "80 shelley\n",
            "81 sink\n",
            "82 soul\n",
            "83 speed\n",
            "84 summar\n",
            "85 summari\n",
            "86 upgrad\n",
            "87 usag\n",
            "88 washington\n",
            "89 access\n",
            "90 activ\n",
            "91 actual\n",
            "92 advanc\n",
            "93 anybodi\n",
            "94 anymor\n",
            "95 appear\n",
            "96 better\n",
            "97 breifli\n",
            "98 bunch\n",
            "99 convict\n",
            "100 corner\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary.filter_extremes(no_below = 15, no_above = 0.1, keep_n = 10000)"
      ],
      "metadata": {
        "id": "ao-0Mci2kc7D"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        " \n",
        "document_num = 20\n",
        "bow_doc_x = bow_corpus[document_num]\n",
        " \n",
        "for i in range(len(bow_doc_x)):\n",
        "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0], \n",
        "                                                     dictionary[bow_doc_x[i][0]], \n",
        "                                                     bow_doc_x[i][1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8VldqMxjNaH",
        "outputId": "efb59c8d-79cf-4017-933b-5f5bee794b75"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word 18 (\"rest\") appears 1 time.\n",
            "Word 166 (\"clear\") appears 1 time.\n",
            "Word 336 (\"refer\") appears 1 time.\n",
            "Word 350 (\"true\") appears 1 time.\n",
            "Word 391 (\"technolog\") appears 1 time.\n",
            "Word 437 (\"christian\") appears 1 time.\n",
            "Word 453 (\"exampl\") appears 1 time.\n",
            "Word 476 (\"jew\") appears 1 time.\n",
            "Word 480 (\"lead\") appears 1 time.\n",
            "Word 482 (\"littl\") appears 3 time.\n",
            "Word 520 (\"wors\") appears 2 time.\n",
            "Word 721 (\"keith\") appears 3 time.\n",
            "Word 732 (\"punish\") appears 1 time.\n",
            "Word 803 (\"california\") appears 1 time.\n",
            "Word 859 (\"institut\") appears 1 time.\n",
            "Word 917 (\"similar\") appears 1 time.\n",
            "Word 990 (\"allan\") appears 1 time.\n",
            "Word 991 (\"anti\") appears 1 time.\n",
            "Word 992 (\"arriv\") appears 1 time.\n",
            "Word 993 (\"austria\") appears 1 time.\n",
            "Word 994 (\"caltech\") appears 2 time.\n",
            "Word 995 (\"distinguish\") appears 1 time.\n",
            "Word 996 (\"german\") appears 1 time.\n",
            "Word 997 (\"germani\") appears 3 time.\n",
            "Word 998 (\"hitler\") appears 1 time.\n",
            "Word 999 (\"livesey\") appears 2 time.\n",
            "Word 1000 (\"motto\") appears 2 time.\n",
            "Word 1001 (\"order\") appears 1 time.\n",
            "Word 1002 (\"pasadena\") appears 1 time.\n",
            "Word 1003 (\"pompous\") appears 1 time.\n",
            "Word 1004 (\"popul\") appears 1 time.\n",
            "Word 1005 (\"rank\") appears 1 time.\n",
            "Word 1006 (\"schneider\") appears 1 time.\n",
            "Word 1007 (\"semit\") appears 1 time.\n",
            "Word 1008 (\"social\") appears 1 time.\n",
            "Word 1009 (\"solntz\") appears 1 time.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model =  gensim.models.LdaMulticore(bow_corpus,\n",
        "                                   num_topics = 8,\n",
        "                                   id2word = dictionary,                                   \n",
        "                                   passes = 10,\n",
        "                                   workers = 2)"
      ],
      "metadata": {
        "id": "55TNWS-uk8H3"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ca50NvS_lSGK",
        "outputId": "6be8a150-e5b1-4a06-fdac-7b5cf4b3d995"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 \n",
            "Words: 0.012*\"armenian\" + 0.011*\"game\" + 0.010*\"team\" + 0.006*\"turkish\" + 0.006*\"player\" + 0.006*\"play\" + 0.005*\"season\" + 0.004*\"basebal\" + 0.004*\"leagu\" + 0.004*\"leav\"\n",
            "\n",
            "\n",
            "Topic: 1 \n",
            "Words: 0.017*\"drive\" + 0.005*\"control\" + 0.005*\"hard\" + 0.005*\"disk\" + 0.004*\"bike\" + 0.004*\"firearm\" + 0.004*\"caus\" + 0.004*\"effect\" + 0.003*\"car\" + 0.003*\"pitt\"\n",
            "\n",
            "\n",
            "Topic: 2 \n",
            "Words: 0.011*\"scsi\" + 0.009*\"wire\" + 0.008*\"power\" + 0.006*\"appl\" + 0.005*\"control\" + 0.005*\"chip\" + 0.005*\"data\" + 0.004*\"connect\" + 0.004*\"circuit\" + 0.004*\"speed\"\n",
            "\n",
            "\n",
            "Topic: 3 \n",
            "Words: 0.010*\"space\" + 0.009*\"nasa\" + 0.005*\"presid\" + 0.005*\"nation\" + 0.004*\"research\" + 0.004*\"program\" + 0.004*\"center\" + 0.004*\"report\" + 0.004*\"health\" + 0.004*\"group\"\n",
            "\n",
            "\n",
            "Topic: 4 \n",
            "Words: 0.011*\"govern\" + 0.009*\"encrypt\" + 0.008*\"secur\" + 0.007*\"chip\" + 0.007*\"israel\" + 0.006*\"clipper\" + 0.006*\"public\" + 0.006*\"isra\" + 0.005*\"protect\" + 0.004*\"key\"\n",
            "\n",
            "\n",
            "Topic: 5 \n",
            "Words: 0.009*\"game\" + 0.008*\"toronto\" + 0.008*\"play\" + 0.007*\"hockey\" + 0.007*\"team\" + 0.006*\"canada\" + 0.005*\"player\" + 0.005*\"columbia\" + 0.004*\"henri\" + 0.004*\"playoff\"\n",
            "\n",
            "\n",
            "Topic: 6 \n",
            "Words: 0.015*\"window\" + 0.014*\"file\" + 0.009*\"program\" + 0.007*\"card\" + 0.006*\"version\" + 0.006*\"softwar\" + 0.006*\"imag\" + 0.005*\"graphic\" + 0.005*\"avail\" + 0.005*\"color\"\n",
            "\n",
            "\n",
            "Topic: 7 \n",
            "Words: 0.010*\"christian\" + 0.006*\"jesus\" + 0.006*\"exist\" + 0.004*\"claim\" + 0.004*\"moral\" + 0.004*\"human\" + 0.004*\"jew\" + 0.004*\"word\" + 0.004*\"religion\" + 0.004*\"life\"\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}