{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN5bl4VeR8k5xM3GtfnQeSM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nisha1365/TECHNICAL_TRAINING_CTS/blob/main/Nisha_2211566_Assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Pyspark and the required jdk"
      ],
      "metadata": {
        "id": "aOvsxlswr21M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "!apt install openjdk-8-headless -qq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5YyhALSr-ld",
        "outputId": "8564932b-da23-400c-f955-5c3db738626e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Using cached pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "Collecting py4j==0.10.9.5\n",
            "  Using cached py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=65f5b0e303370de0e9266d599bc48648fd9fedf454a58e16262b38f995956188\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n",
            "E: Unable to locate package openjdk-8-headless\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "metadata": {
        "id": "yhT7wMpUsUM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "metadata": {
        "id": "zHdbU2jDs6D-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4lDemi1FuG1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql import Window\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import sum as Fsum\n",
        "from pyspark.sql.types import ArrayType, BooleanType, LongType, FloatType, IntegerType\n",
        "from pyspark.sql.functions import lit, udf, struct, countDistinct, collect_list, avg, count, col\n",
        "from pyspark.ml.feature import VectorAssembler, Normalizer, StandardScaler\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
        "from pyspark.ml import Pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
      ],
      "metadata": {
        "id": "cP8NPA3rtRTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning the Dataset\n",
        "df = df.drop(*['artist','song','firstName', 'lastName', 'id_copy'])             # dropping some irrelevant columns\n",
        "df = df.dropna(how = 'any', subset = ['userId', 'sessionId'])                   # droppping some potential NA values\n",
        "df = df.filter(df.userId!='').orderBy([\"userId\", \"ts\"], ascending=[True, True]) # filtering out the invalid Ids\n",
        "df = df.withColumn(\"userId\", df[\"userId\"].cast(IntegerType()))\n"
      ],
      "metadata": {
        "id": "TVQyMuCFwIPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Some new columns were made in this step to make the data exploration easier,\n",
        "# the Feature engineering step comes later\n",
        "# Making the level_shift Column\n",
        "# This column tells us how many times did the customer switched\n",
        "# from paid to free service\n",
        "window1 = Window.partitionBy().orderBy([\"userId\", \"ts\"])\n",
        "df = df.withColumn(\"level_shift\", (df.level!=F.lag(df.level).over(window1)) | \n",
        "                   (df.userId!=F.lag(df.userId).over(window1)))\n",
        "df=df.fillna({'level_shift':0})\n",
        "df= df.withColumn(\"level_shift\", F.when(df[\"level_shift\"]==False, 0).otherwise(1))\n"
      ],
      "metadata": {
        "id": "LWzx75nAxd5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making the last_ts column\n",
        "# This column will help us to select only records that happened in the\n",
        "# last 2 weeks of customer activity\n",
        "# The idea is that customer behavior should be different shortly before\n",
        "# the churn happened\n",
        "df= df.withColumn(\"ts\", df.ts/1000)                        # trimming the last three zeros from the UNIX time (miliseconds)\n",
        "df= df.withColumn(\"registration\", df.registration/1000)"
      ],
      "metadata": {
        "id": "kFSj6BlZyKHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window2 = Window.partitionBy(\"userId\")\n",
        "df= df.withColumn(\"last_ts\", F.max('ts').over(window2))\n",
        "df=df.filter(df.last_ts - df.ts < 1300000) # approx no of sec in a 2 weeks"
      ],
      "metadata": {
        "id": "J6mPpZsHyhds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making the Columns: pages_per_session, diff_time\n",
        "# pages_per_session is number of pages per session\n",
        "# diff_time is a number of days since a specific page was visited\n",
        "window3 = Window.partitionBy([\"userId\", \"sessionId\"])\n",
        "df= df.withColumn(\"pages_per_session\", F.max('ItemInSession').over(window3))\n",
        "df = df.withColumn(\"ts_time\",F.to_timestamp(df.ts))                    #  unix to datetime\n",
        "df = df.withColumn(\"last_ts_time\",F.to_timestamp(df.last_ts))          # unix to datetime"
      ],
      "metadata": {
        "id": "iLW27lw6zcUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn(\"diff_time\",F.datediff(df.last_ts_time, df.ts_time))  # how many days ago was the page visited\n",
        "df=df.orderBy([\"userId\", \"ts\"], ascending=[True, True])\n",
        "df.createOrReplaceTempView('data');                                    # Create a Temp Table to be used for SQL queries"
      ],
      "metadata": {
        "id": "iHzkzrrUzfoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The column \"page\" seems to be most informative in the whole dataset\n",
        "# It shows which pages of the service were visited by users, timestamp is also provided\n",
        "# This column can be used to engineer useful features\n",
        "df.select('page','UserId').groupby('page').agg({'page':'count'}).select('page','count(page)').show()"
      ],
      "metadata": {
        "id": "Bdltf-8k0D_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema();"
      ],
      "metadata": {
        "id": "prZRqlF-0rHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Investigation if there are differences between churned and non-churned users\n",
        "# label             - 0 if non_churned, 1 if churned\n",
        "# song_count        - avg number of songs played by churned/non_churned users\n",
        "# error             - avg number of errors occuring \n",
        "# friends           - avg number of \"friends\" on thhe application\n",
        "# playlist_count    - avg number of visits to the Playlist page\n",
        "# thumbs_up         - avg number of clicking the 'thumbs up'\n",
        "# thumbs_down       - avg number of clicking the 'thumbs down'\n",
        "# downgrade         - avg number of visits to the downgrade page\n",
        "# count_session_dist- avg number of sessions made\n",
        "# count_diff_time   - avg number of days (in the last two weeks) in which the user used the app\n",
        "# pages per session - avg numbers of pages (or any activity or changes) per session\n",
        "# duration          - avg number of days since the user joined (division with 86400 as a proxy of seconds within a day)\n",
        "# level_shift       - avg number of level changes (free, paid) per customer\n",
        "# usage_time        - avg total time spent using the app\n",
        "stats = spark.sql(\" WITH prep as( \\\n",
        "SELECT userId, \\\n",
        "max(churn)                                                          as label, \\\n",
        "count(case when page = 'NextSong' then userId else null end)        as song_count, \\\n",
        "count(case when page = 'Error' then userId else null end)           as error, \\\n",
        "count(case when page = 'Add Friend' then userId else null end)      as friends, \\\n",
        "count(case when page = 'Add to Playlist' then userId else null end) as playlist_count, \\\n",
        "count(case when page = 'Thumbs Up' then userId else null end)       as thumbs_up, \\\n",
        "count(case when page = 'Thumbs Down' then userId else null end)     as thumbs_down, \\\n",
        "count(case when page = 'Downgrade' then userId else null end)       as downgrade, \\\n",
        "count(distinct sessionId)                                           as count_session_dist, \\\n",
        "count(distinct diff_time)                                           as count_diff_time, \\\n",
        "avg(distinct pages_per_session)                                     as pages_per_session, \\\n",
        "(max(ts) - min(registration))/86400                                 as duration, \\\n",
        "sum(level_shift)                                                    as level_shift, \\\n",
        "sum(length)                                                         as usage_time \\\n",
        "FROM data \\\n",
        "GROUP BY userId) \\\n",
        "SELECT label, \\\n",
        "count(label)             as cnt, \\\n",
        "avg(song_count)          as song_count, \\\n",
        "avg(error)               as error, \\\n",
        "avg(friends)             as friends, \\\n",
        "avg(playlist_count)      as playlist_count, \\\n",
        "avg(thumbs_up)           as thumbs_up, \\\n",
        "avg(thumbs_down)         as thumbs_down, \\\n",
        "avg(downgrade)           as downgrade, \\\n",
        "avg(count_session_dist)  as count_session_dist, \\\n",
        "avg(count_diff_time)     as count_diff_time, \\\n",
        "avg(pages_per_session)   as pages_per_session, \\\n",
        "avg(duration)            as duration, \\\n",
        "avg (level_shift)        as level_shift, \\\n",
        "avg(usage_time)          as usage_time \\\n",
        "FROM prep \\\n",
        "GROUP BY label\")\n",
        "# We can see that for most dimensions/features there are differences between\n",
        "# churned and non-churned users\n",
        "stats.toPandas()"
      ],
      "metadata": {
        "id": "_KBMeuPy1pSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Enigneering\n",
        "# Based on the previous analysis, all 14 investigated features will be included. \n",
        "# Here I am making a Temp Table which holds all the features.\n",
        "# The temp table will be used as model input\n",
        "# All data is aggregated per userId\n",
        "features = spark.sql(\"SELECT userId, \\\n",
        "max(churn)                                                          as label, \\\n",
        "count(case when page = 'NextSong' then userId else null end)        as song_count, \\\n",
        "count(case when page = 'Error' then userId else null end)           as error, \\\n",
        "count(case when page = 'Add Friend' then userId else null end)      as friends, \\\n",
        "count(case when page = 'Add to Playlist' then userId else null end) as playlist_count, \\\n",
        "count(case when page = 'Thumbs Up' then userId else null end)       as thumbs_up, \\\n",
        "count(case when page = 'Thumbs Down' then userId else null end)     as thumbs_down, \\\n",
        "count(case when page = 'Downgrade' then userId else null end)       as downgrade, \\\n",
        "count(distinct sessionId)                                           as count_session_dist, \\\n",
        "count(distinct diff_time)                                           as count_diff_time, \\\n",
        "round(avg(distinct pages_per_session),0)                            as pages_per_session, \\\n",
        "round((max(ts) - min(registration))/86400,0)                        as duration, \\\n",
        "round(sum(level_shift),0)                                           as level_shift, \\\n",
        "round(sum(length),0)                                                as usage_time \\\n",
        "FROM data \\\n",
        "GROUP BY userId\");\n",
        "features.createOrReplaceTempView('features');\n",
        "features=features.na.drop()"
      ],
      "metadata": {
        "id": "DNmVzn9N1xTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training, test = features.randomSplit([0.8,0.2])"
      ],
      "metadata": {
        "id": "0mAGynG32a1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make VectorAssembler - this is a Pypark specific step\n",
        "# All input features must be in one column before feeding into the model\n",
        "assembler = VectorAssembler(inputCols=[\"userId\",\"song_count\",\"error\",\"friends\",\"playlist_count\", \\\n",
        "                                       \"thumbs_up\",\"thumbs_down\",\"downgrade\", \"count_session_dist\",\\\n",
        "                                       \"count_diff_time\",\"pages_per_session\", \"duration\",\"level_shift\",\\\n",
        "                                       \"usage_time\"], \\\n",
        "                            outputCol=\"inputFeatures\")"
      ],
      "metadata": {
        "id": "b6feUduN3WS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize Data\n",
        "scaler = Normalizer(inputCol = \"inputFeatures\",outputCol=\"features\")"
      ],
      "metadata": {
        "id": "aljGiJjC362E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression()\n",
        "gbt = GBTClassifier()\n",
        "rf = RandomForestClassifier()\n"
      ],
      "metadata": {
        "id": "e4elUkYo4Pxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Building pipelines\n",
        "pipeline1 = Pipeline(stages=[assembler, scaler,lr])\n",
        "pipeline2 = Pipeline(stages=[assembler, scaler,gbt])\n",
        "pipeline3 = Pipeline(stages=[assembler, scaler,rf])"
      ],
      "metadata": {
        "id": "_GJgFuje4xsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# metric chosen is f1 (we want to catch true positives (churn customers), but\n",
        "# we do not want to waste money on false positives (investing in retaining \n",
        "# non-churn customers, which are loyal anyway)\n",
        "# Note that Recall might also be justified to use here (if the cost offalse\n",
        "# positives is low)\n",
        "paramgrid =ParamGridBuilder()\\\n",
        ".addGrid(lr.regParam, [0.0, 0,1])\\\n",
        ".addGrid(lr.maxIter, [10])\\\n",
        ".build()"
      ],
      "metadata": {
        "id": "HW5Poa575lDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = MulticlassClassificationEvaluator(metricName=\"f1\")"
      ],
      "metadata": {
        "id": "NcbS1WmV6Hur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crossval= CrossValidator(estimator=pipeline1,  \n",
        "                         estimatorParamMaps=paramgrid,\n",
        "                         evaluator = evaluator , \n",
        "                         numFolds=3\n",
        "                        )"
      ],
      "metadata": {
        "id": "r7ZA5itA6O-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cvModel1 = crossval.fit(training)"
      ],
      "metadata": {
        "id": "0vLdgRSg7CHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator.evaluate(cvModel1.transform(test))"
      ],
      "metadata": {
        "id": "MjRTaN2t7W9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Boosted tree Classifier"
      ],
      "metadata": {
        "id": "bp_Q6ZGv7yQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify multiple parameters in the paramgrid, in case you have\n",
        "# enough processing power \n",
        "paramgrid1 =ParamGridBuilder().build()"
      ],
      "metadata": {
        "id": "OkgDgEsY7geH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator=MulticlassClassificationEvaluator(metricName=\"f1\")"
      ],
      "metadata": {
        "id": "5pPd-SNm8DWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crossval= CrossValidator(estimator=pipeline2,  \n",
        "                         estimatorParamMaps=paramgrid1,\n",
        "                         evaluator=evaluator, \n",
        "                         numFolds=3\n",
        "                        )"
      ],
      "metadata": {
        "id": "-o5sm9sx9BiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cvModel2 = crossval.fit(training)"
      ],
      "metadata": {
        "id": "MDZXmCow9YL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator.evaluate(cvModel2.tranform(test))"
      ],
      "metadata": {
        "id": "yKA3w7tF9cUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest Classifier"
      ],
      "metadata": {
        "id": "JZiZphBg9llb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paramgrid2 = ParamGridBuilder().build()"
      ],
      "metadata": {
        "id": "zxNajK1Q9p69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator=MulticlassClassificationEvaluator(metrixName=\"f1\")"
      ],
      "metadata": {
        "id": "YJzIDr0F93Vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crossval = CrossValidator(estimator=pipeline3,\n",
        "                          estimatorParamMaps=paramgrid2,\n",
        "                          evaluator=evaluator,\n",
        "                          numFolds=3\n",
        "                          )"
      ],
      "metadata": {
        "id": "GuhmXvUt-lQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cvModel3 = crossval.fit(training)"
      ],
      "metadata": {
        "id": "Gql13D2G-484"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator.evaluate(cvModel3.transform(test))"
      ],
      "metadata": {
        "id": "PdbwVOYc-_yL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions=cvModel2.transform(test)"
      ],
      "metadata": {
        "id": "86j76M-F_Hdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def roc(ax, predictions, labels, title='ROC curve'):\n",
        "    pp = predictions.toPandas()['probability'].apply(lambda x:x[1]).values\n",
        "    tpr, fpr, _ = roc_curve(labels, pp)\n",
        "    ax.plot(tpr, fpr)\n",
        "    ax.set_facecolor('xkcd:wheat')\n",
        "    ax.set_xlabel('False Positive Rate')\n",
        "    ax.set_ylabel('True Positive Rate')\n",
        "    ax.set_title(title)\n",
        "    \n",
        "#plt.clf() # to be used for AWS EMR\n",
        "labels=predictions.toPandas()['label']\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "roc(ax, predictions,labels)"
      ],
      "metadata": {
        "id": "hurwmqZT_Lm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JmxXpnC74F4z"
      }
    }
  ]
}