{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nisha1365/TECHNICAL_TRAINING_CTS/blob/main/spark_introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqsKMPn0h2nA",
        "outputId": "fde79dec-6579-430d-9d23-72eca42b95fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 50 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 54.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=36a729147dad32f31a0cae671803bb568977bf973bce0c03e51f47e2d606a14f\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive"
      ],
      "metadata": {
        "id": "9ehTZDoUiQlJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install openjdk-8-jdk-headless -qq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkQsPyZbjERt",
        "outputId": "4c3c7a27-17be-497f-ad05-7fe1c802a9dd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 2 newly installed, 0 to remove and 22 not upgraded.\n",
            "Need to get 36.6 MB of archives.\n",
            "After this operation, 143 MB of additional disk space will be used.\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "(Reading database ... 123941 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u342-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u342-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "NSPuglBnjjp8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"JAVA_HOME\"]=\"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "metadata": {
        "id": "KmG5V4T8jzky"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "sc=pyspark.SparkContext(appName=\"Spark_Introduction\")"
      ],
      "metadata": {
        "id": "cw7lRBMVkS4g"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "log_of_songs = [\n",
        "        \"Despacito\",\n",
        "        \"Nice for what\",\n",
        "        \"No tears left to cry\",\n",
        "        \"Despacito\",\n",
        "        \"Havana\",\n",
        "        \"In my feelings\",\n",
        "        \"Nice for what\",\n",
        "        \"despacito\",\n",
        "        \"All the stars\"\n",
        "]"
      ],
      "metadata": {
        "id": "6U9cgvS0n5y7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#parallelize the log_of_songs to use with spark\n",
        "distributed_song_log = sc.parallelize(log_of_songs)"
      ],
      "metadata": {
        "id": "8eJmJM8zo8eM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_song_to_lowercase(song):\n",
        "  return song.lower()\n",
        "\n",
        "convert_song_to_lowercase(\"Havana\")  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ptb10Vjgp6E1",
        "outputId": "8825f50c-f3b9-4c5b-fb7e-d541d91fd1c4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'havana'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'Venkat Lakshmi Pathi V'.title()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "O4F-I4hxqeMQ",
        "outputId": "13867e32-0cc2-4887-e1a1-396ae64e29af"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Venkat Lakshmi Pathi V'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "distributed_song_log.map(convert_song_to_lowercase)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eyopwx24qqKK",
        "outputId": "1e8b8964-73b9-4deb-dfbd-ad3b4bbf7d37"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonRDD[1] at RDD at PythonRDD.scala:53"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spark does not actually execute the map step unless it needs to.\n",
        "\n",
        "RDD in the output refers to resilient distributed dataset.RDDs are exactly what they are - fault tolerant datasets distributed across a cluster. This is how Spark stores data.\n",
        "\n",
        "To get spark to actually run the map step, you need to use an 'action'. one available action is the collect method. The collect() method takes the result from all the clusters and \"collects\" them into a single list on the master node."
      ],
      "metadata": {
        "id": "LCi7QAg2bMOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distributed_song_log.map(convert_song_to_lowercase).collect()"
      ],
      "metadata": {
        "id": "hZcI2DJTb9QO",
        "outputId": "cc5ab3ff-4aa3-4df4-dcb2-1d06252bf70d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['despacito',\n",
              " 'nice for what',\n",
              " 'no tears left to cry',\n",
              " 'despacito',\n",
              " 'havana',\n",
              " 'in my feelings',\n",
              " 'nice for what',\n",
              " 'despacito',\n",
              " 'all the stars']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note as well that spark is not changing the original dataset. Spark is merely making a copy. You can see this by running collect() on original dataset"
      ],
      "metadata": {
        "id": "uf2mWAcscIlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distributed_song_log.collect()"
      ],
      "metadata": {
        "id": "wgpJvVRhcb_G",
        "outputId": "2c907705-2ee2-4ce5-8a71-002974f6c27f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Despacito',\n",
              " 'Nice for what',\n",
              " 'No tears left to cry',\n",
              " 'Despacito',\n",
              " 'Havana',\n",
              " 'In my feelings',\n",
              " 'Nice for what',\n",
              " 'despacito',\n",
              " 'All the stars']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You do not always have to write a custom funtion map step. you can use lambda functions as well but Python functions like string.lower().\n",
        "\n"
      ],
      "metadata": {
        "id": "g1yYtfjecgLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distributed_song_log.map(lambda song: song.lower()).collect()"
      ],
      "metadata": {
        "id": "m678pptic78Z",
        "outputId": "6c35974c-4f7a-4dbe-8d0b-adc5d30bb71a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['despacito',\n",
              " 'nice for what',\n",
              " 'no tears left to cry',\n",
              " 'despacito',\n",
              " 'havana',\n",
              " 'in my feelings',\n",
              " 'nice for what',\n",
              " 'despacito',\n",
              " 'all the stars']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "distributed_song_log.map(lambda x : x.lower()).collect"
      ],
      "metadata": {
        "id": "NUTTOUp9daq8",
        "outputId": "3f37d5b9-91d3-4427-83b8-e95c1182a6ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method RDD.collect of PythonRDD[4] at RDD at PythonRDD.scala:53>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g-T4bAXodupq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}